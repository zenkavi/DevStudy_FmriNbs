{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Experiments expanding on Ito et al. (2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARMA\n",
    "from statsmodels.tsa.filters.filtertools import recursive_filter\n",
    "\n",
    "## Import custom modules\n",
    "# Primary module with most model functions\n",
    "import model\n",
    "# Module for FC regression\n",
    "import multregressionconnectivity as mreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lambda x: np.tanh(x)\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "def scatter_two_vars(a,b):\n",
    "    d = {'Var1': a, 'Var2': b}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    p = sns.regplot(x='Var1', y='Var2', data = df)\n",
    "    p.text(min(a), max(b), \"r = %s\"%(str(round(np.corrcoef(a, b)[1][0],3))), horizontalalignment='left', color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: GLM recovery of simulated task activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create network\n",
    "\n",
    "One hub and two local networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set up subject network matrix ####\n",
    "# Parameters for subject's networks\n",
    "ncommunities = 3\n",
    "innetwork_dsity = .60\n",
    "outnetwork_dsity = .08\n",
    "hubnetwork_dsity = .25\n",
    "\n",
    "nodespercommunity = 35\n",
    "totalnodes = nodespercommunity*ncommunities\n",
    "\n",
    "# Construct structural matrix\n",
    "W = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "G = model.generateSynapticNetwork(W, showplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate resting state activity using information flow model\n",
    "\n",
    "Apply neural networl]k model **(Eq 3 in paper)** to the connectivity matrix and calculate each nodes' activity for each time point\n",
    "\n",
    "**Note that this is still in synaptic space (i.e. not convolved)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up simulation parameters\n",
    "#Tmaxrest = 60000 # 1min resting state data\n",
    "Tmaxrest = 300000 # 5min resting state data\n",
    "dt = 1.0\n",
    "tau = 1.0\n",
    "g = 1.0\n",
    "s = 1.0\n",
    "TRLength = 100\n",
    "\n",
    "restdata = model.networkModel(G, \n",
    "                              Tmax=Tmaxrest,\n",
    "                              dt=dt,\n",
    "                              g=g,\n",
    "                              s=s,\n",
    "                              tau=tau,\n",
    "                              I=None,\n",
    "                              noise = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(restdata, aspect='auto',origin='lower')\n",
    "plt.title('Simulated resting-state activity', y=1.04, fontsize=16)\n",
    "plt.ylabel('Regions',fontsize=14)\n",
    "plt.xlabel('Time (s)',fontsize=14)\n",
    "plt.xticks(np.arange(0,Tmaxrest+1,10000),np.arange(0,Tmaxrest+1,10000)/100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolve resting state activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restfmri = model.convolveTimeseries(restdata,\n",
    "                                    samplingrate=dt,\n",
    "                                    TRLength=TRLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(restfmri, aspect='auto',origin='lower')\n",
    "plt.title('Simulated fMRI resting-state activity', y=1.04, fontsize=16)\n",
    "plt.ylabel('Regions',fontsize=14)\n",
    "plt.xlabel('Time (s)',fontsize=14)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recover connectivity matrix from resting state activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcmat = np.corrcoef(restfmri)\n",
    "# 0 out the diagonal\n",
    "np.fill_diagonal(fcmat,0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(fcmat, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Simulated fMRI resting-state FC \\nSingle Subject\\nPearsonFC', y=1.04, fontsize=16)\n",
    "plt.xlabel('Regions',fontsize=14)\n",
    "plt.ylabel('Regions', fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcmat_mreg = mreg.multregressionconnectivity(restfmri)\n",
    "# 0 out the diagonal\n",
    "np.fill_diagonal(fcmat_mreg,0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(fcmat_mreg, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Simulated fMRI resting-state FC\\nSingle Subject\\nMultipleRegressionFC', y=1.04, fontsize=16)\n",
    "plt.xlabel('Regions',fontsize=14)\n",
    "plt.ylabel('Regions', fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How **quantitatively** similar is the fc_mat to the weight matrix G?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fcmat.flatten(), G.flatten())\n",
    "np.corrcoef(fcmat.flatten(), G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fcmat_mreg.flatten(), G.flatten())\n",
    "np.corrcoef(fcmat_mreg.flatten(), G.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate task activity using resting state\n",
    "\n",
    "- How do you decide the task's spatial specificity, i.e. which network and nodes within a network it affects primarily? \n",
    "    - In the simulations the approach is: For topdown tasks only the hub network is simulated. E.g. for task 1 the first quarter of nodes are stimulated, for task 2 the next quarter etc. \n",
    "    - For topdown and bottom up (where a bug was fixed) it is a bit more complicated. E.g. for task 5 the first quarter of the hub network and the nodes of network 1 (first local network) that connect to the hub network (network 0) are stimulated\n",
    "\n",
    "#### Hub network stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ci = np.repeat(np.arange(ncommunities),nodespercommunity) # Construct a community affiliation vector\n",
    "hub_ind = np.where(Ci==0)[0] # Identify the regions associated with the hub network (hub network is by default the 0th network)\n",
    "\n",
    "# Set number of time points for each task\n",
    "#Tmax = 10000\n",
    "Tmax = 300000 #increased to 5 minutes\n",
    "\n",
    "T = np.arange(0,Tmax,dt)\n",
    "\n",
    "taskdata = {}\n",
    "stimtimes = {}\n",
    "    \n",
    "# Construct timing array for convolution -- this timing is irrespective of the task being performed\n",
    "# Tasks are only determined by which nodes are stimulated\n",
    "tasktiming = np.zeros((1,len(T)))\n",
    "for t in range(len(T)):\n",
    "    if t%2000>500 and t%2000<1000:\n",
    "    #if t>0 and t%1000==0: #Changed to a task with spikes as activity\n",
    "        tasktiming[0,t] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdown_only = range(1,2)\n",
    "task = 1\n",
    "\n",
    "taskcount = task-np.min(topdown_only)\n",
    "stimsize = np.floor(nodespercommunity/4.0)\n",
    "stim_nodes = np.arange((taskcount)*stimsize,(taskcount)*stimsize+stimsize,dtype=int)\n",
    "stimtimes[task] = np.zeros((totalnodes,len(T)))\n",
    "\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        # Task stimulation every 10 seconds for 4 seconds, excluding the first 10 seconds\n",
    "        # Changed to spike every second for 10 minues\n",
    "        stimtimes[task][stim_nodes,t] = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block design ~~Spike task~~ looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T[:10000], tasktiming[0,:10000])\n",
    "plt.ylim(top = 1.2, bottom = -0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activated nodes in the hub network *only* (making it a top-down task) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskdata[task] = model.networkModel(G,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(taskdata[task], aspect='auto',origin='lower')\n",
    "plt.title('Simulated single topdown task activity', y=1.04, fontsize=16)\n",
    "plt.ylabel('Regions',fontsize=14)\n",
    "plt.xlabel('Time (s)',fontsize=14)\n",
    "plt.xticks(np.arange(0,Tmax+1,10000),np.arange(0,Tmax+1,10000)/100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolve task activity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplingrate=1.0\n",
    "# Convolve simulated task data into fMRI signal\n",
    "task_bold = model.convolveTimeseries(taskdata[task],\n",
    "                               samplingrate=samplingrate, \n",
    "                               TRLength=TRLength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(task_bold, aspect='auto',origin='lower')\n",
    "plt.title('Simulated single topdown task fMRI activity', y=1.04, fontsize=16)\n",
    "plt.ylabel('Regions',fontsize=14)\n",
    "plt.xlabel('Time (s)',fontsize=14)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run GLM on convolved task activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip_BOLD = int(TRLength)\n",
    "# Temporally downsample task timing to seconds (before convolving)\n",
    "timingconv = tasktiming[:,::n_skip_BOLD]\n",
    "timingconv.shape = (timingconv.shape[1],)\n",
    "hrfsample_rate=1.0 # HRF is sampled at seconds\n",
    "hrfsample_times = np.arange(0, 30, hrfsample_rate, dtype=float)\n",
    "hrf_at_simsample = model.hrf(hrfsample_times)\n",
    "hrfconvtime = np.convolve(timingconv, hrf_at_simsample)\n",
    "n_to_remove = len(hrf_at_simsample) - 1\n",
    "convolved = hrfconvtime[:-n_to_remove]\n",
    "# Output\n",
    "timing_convolved_downsampled = convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_betas_postfmri, task_resids_postfmri, task_tvals_postfmri, task_betas_ci_postfmri = model.runTaskGLM(task_bold, timing_convolved_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of GLM. Vertical lines indicate network boundaries. Stimulated nodes are the first eight in the hub network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(task_tvals_postfmri)\n",
    "plt.ylabel('Uncorrected t-value',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axhline(y=3,linewidth=2, color='red', ls = \"--\")\n",
    "plt.axvline(x=35,linewidth=2, color='black', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='black', ls = \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uperror = task_betas_ci_postfmri[:,1]\n",
    "downerror = task_betas_ci_postfmri[:,0]\n",
    "errorbars = np.concatenate(([uperror], [downerror]), axis=0)\n",
    "\n",
    "plt.errorbar(np.arange(totalnodes), task_betas_postfmri, yerr=errorbars, fmt = 'o')\n",
    "plt.ylabel('Beta (with 95% CI)',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_stim_nodes = stim_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between betas and weights from the connectivity matrix\n",
    "\n",
    "Extract average connectivity between each node and the nodes stimulated by task.  \n",
    "Correlate these average weights with betas for each node.\n",
    "\n",
    "NOTE: The weight matrix is *NOT* symmetric (I think) because afferent and efferent connection weights need not be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "check_symmetric(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract average connectivity of each node with the stim nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afferent_cons = np.empty((0,G.shape[0]), float)\n",
    "efferent_cons = np.empty((0,G.shape[0]), float)\n",
    "for i in range(G.shape[0]):\n",
    "    efferent_cons = np.append(efferent_cons, [G[hub_stim_nodes,i].mean()])\n",
    "    afferent_cons = np.append(afferent_cons, [G[i,hub_stim_nodes].mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Beta': task_betas_postfmri[8:], 'Connectivity': efferent_cons[8:]}\n",
    "df = pd.DataFrame(data=d)\n",
    "p = sns.regplot(x='Beta', y='Connectivity', data = df)\n",
    "p.text(min(task_betas_postfmri[8:]), max(efferent_cons[8:]), \"r = %s\"%(str(round(np.corrcoef(task_betas_postfmri[8:], efferent_cons[8:])[1][0],3))), horizontalalignment='left', color='black')\n",
    "p.set_title('Correlation between betas and efferent connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Beta': task_betas_postfmri[8:], 'Connectivity': afferent_cons[8:]}\n",
    "df = pd.DataFrame(data=d)\n",
    "p = sns.regplot(x='Beta', y='Connectivity', data = df)\n",
    "p.text(min(task_betas_postfmri[8:]), max(afferent_cons[8:]), \"r = %s\"%(str(round(np.corrcoef(task_betas_postfmri[8:], afferent_cons[8:])[1][0],3))), horizontalalignment='left', color='black')\n",
    "p.set_title('Correlation between betas and afferent connections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting GLM using whole system data\n",
    "\n",
    "### Uncorrected GLM at neural network level\n",
    "\n",
    "Using first third of the data for speed of estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskdata_short = copy.copy(taskdata[1][:,:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pshift(y,p):\n",
    "            y_lag = np.roll(y, p)\n",
    "            y_lag[:p] = 0\n",
    "            return y_lag\n",
    "\n",
    "def recover_pars(x, y, p = 1):\n",
    "        \n",
    "    ntimepoints = y.shape[1]\n",
    "    nregions = y.shape[0]\n",
    "    \n",
    "    #Initialize empty variables\n",
    "    task_glm = np.zeros((nregions))\n",
    "    cur_node_ext_ucr = np.zeros((nregions)) \n",
    "    weight_matrix_ext_ucr = np.zeros((nregions, nregions-1))\n",
    "    task_ext_ucr = np.zeros((nregions))\n",
    "    cur_node_ext_arc = np.zeros((nregions))\n",
    "    weight_matrix_ext_arc = np.zeros((nregions, nregions-1))\n",
    "    task_ext_arc = np.zeros((nregions))\n",
    "    cur_node_ext_pw = np.zeros((nregions))\n",
    "    weight_matrix_ext_pw = np.zeros((nregions, nregions-1))\n",
    "    task_ext_pw = np.zeros((nregions))\n",
    "\n",
    "    #design matrix/task regressor\n",
    "    task_reg = x.T\n",
    "    \n",
    "    for region in range(0, nregions):\n",
    "    \n",
    "    #STANDARD GLM  \n",
    "        cur_y = y[region,:]\n",
    "        mod_glm = sm.OLS(cur_y, task_reg)\n",
    "        res_glm = mod_glm.fit()\n",
    "        task_glm[regions] = res_glm.params[0]\n",
    "        \n",
    "    #EXTENDED GLM\n",
    "    #UCR pars\n",
    "        \n",
    "        # New y: Shift time course up and drop last time point to model activity in next time step\n",
    "        cur_yp1 = np.roll(cur_y, -1)[:-1]\n",
    "        \n",
    "        #Make design matrix\n",
    "        # Add current nodes activity in current time step dropping last time step\n",
    "        cur_node = cur_y[:-1].reshape(-1,1)\n",
    "        cur_node_t = np.apply_along_axis(phi, 0, cur_node)\n",
    "        \n",
    "        # Add other nodes' activity in current time step dropping last time step\n",
    "        drop_region = [region]\n",
    "        other_nodes = np.delete(taskdata_short_pw, drop_region, axis=0)\n",
    "        other_nodes = other_nodes[:,:-1]\n",
    "        other_nodes = other_nodes.T\n",
    "        other_nodes_t = np.apply_along_axis(phi, 0, other_nodes)\n",
    "        \n",
    "        ucr_des_mat = np.concatenate((cur_node_t, other_nodes_t), 1)\n",
    "        \n",
    "        # Add task activity in current time step\n",
    "        ucr_des_mat = np.concatenate((ucr_des_mat, task_reg[:-1,:]), 1)\n",
    "        \n",
    "        #Run model and extract parameters\n",
    "        mod_ext_ucr = sm.OLS(cur_yp1, ucr_des_mat)\n",
    "        res_ext_ucr = mod_ext_ucr.fit()\n",
    "        cur_node_ext_ucr[region] = res_ext_ucr.params[0]\n",
    "        weight_matrix_ext_ucr[region:] = res_ext_ucr.params[1:-1]\n",
    "        task_ext_ucr[region] = res_ext_ucr.params[-1]\n",
    "    \n",
    "    #ARC pars\n",
    "        # Add untransformed activity in current node for current time step\n",
    "        arc_des_mat = np.concatenate((ucr_des_mat, cur_node), 1)\n",
    "        \n",
    "        # Add transformed activity in current node from previous time step\n",
    "        cur_node_m1 = np.roll(cur_node, 1)\n",
    "        cur_node_m1 = np.insert(cur_node, 0, 0)\n",
    "        cur_node_m1 = cur_node_m1.reshape(-1,1)\n",
    "        cur_node_m1_t = np.apply_along_axis(phi, 0, cur_node_m1)\n",
    "        arc_des_mat = np.concatenate((arc_des_mat, cur_node_m1_t), 1)\n",
    "        \n",
    "        # Add transformed activity from other nodes from previous time step\n",
    "        other_nodes_m1 = np.roll(other_nodes, 1)\n",
    "        other_nodes_m1 = np.insert(other_nodes, 0, 0, axis=0)\n",
    "        other_nodes_m1 = other_nodes_m1.T\n",
    "        other_nodes_m1_t = np.apply_along_axis(phi, 0, other_nodes_m1)\n",
    "        arc_des_mat = np.concatenate((arc_des_mat, other_nodes_m1_t), 1)\n",
    "        \n",
    "        # Add task activity from previous time step\n",
    "        task_reg_m1 = np.roll(task_reg[:-1,:], 1)\n",
    "        task_reg_m1 = np.insert(task_reg_m1, 0, 0)\n",
    "        \n",
    "        arc_des_mat = np.concatenate((ucr_des_mat, task_reg_m1), 1)\n",
    "        \n",
    "        #Run model and extract parameters\n",
    "        mod_ext_arc = sm.OLS(cur_yp1, arc_des_mat)\n",
    "        res_ext_arc = mod_ext_arc.fit()\n",
    "        cur_node_ext_arc[region] = res_ext_arc.params[0]\n",
    "        weight_matrix_ext_arc[region:] = res_ext_arc.params[1:-1]\n",
    "        task_ext_ucr[region] = res_ext_arc.params[-1]\n",
    "        \n",
    "    #PW pars\n",
    "    \n",
    "        # Extract errors from res_ext_ucr\n",
    "        err_ext_ucr = res_ext_ucr.resid\n",
    "        \n",
    "        # Run AR(p) model on residuals\n",
    "        try:\n",
    "            ar_mod = ARMA(err_ext_ucr, order=(p, 0))\n",
    "            ar_res = ar_mod.fit(trend=\"nc\")\n",
    "            \n",
    "        # Prewhiten cur_yp1 and ucr_des_mat\n",
    "            shift_y = pshift(cur_yp1, p)\n",
    "            shift_X = pshift(ucr_des_mat, p)\n",
    "            mpw_y = cur_yp1 - (ar_res.params*shift_y)\n",
    "            mpw_X = ucr_des_mat - (ar_res.params*shift_X)\n",
    "            mod_ext_pw = sm.OLS(mpw_y, mpw_X)\n",
    "            res_ext_pw = mod_ext_pw.fit()\n",
    "            cur_node_ext_pw[region] = res_ext_pw.params[0]\n",
    "            weight_matrix_ext_pw[region:] = res_ext_pw.params[1:-1]\n",
    "            task_ext_pw[region] = res_ext_pw.params[-1]\n",
    "        \n",
    "        except:\n",
    "            print('Whitening failed!')\n",
    "            cur_node_ext_pw[region] = np.nan\n",
    "            weight_matrix_ext_pw[region:] = np.nan\n",
    "            task_ext_pw[region] = np.nan\n",
    "    \n",
    "    \n",
    "    out = {'task_glm':task_glm,\n",
    "           'cur_node_ext_ucr':cur_node_ext_ucr,\n",
    "           'weight_matrix_ext_ucr':weight_matrix_ext_ucr,\n",
    "           'task_ext_ucr': task_ext_ucr,\n",
    "           'cur_node_ext_arc':cur_node_ext_arc,\n",
    "           'weight_matrix_ext_arc':weight_matrix_ext_arc,\n",
    "           'task_ext_arc':task_ext_arc,\n",
    "           'cur_node_ext_pw':cur_node_ext_pw,\n",
    "           'weight_matrix_ext_pw':weight_matrix_ext_pw,\n",
    "           'task_ext_pw':task_ext_pw}\n",
    "    \n",
    "    return (out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected GLM at neural network level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task betas reduced after correction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current node betas == 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other node betas recapitulate connectivity matrix?\n",
    "\n",
    "**Relationship between other nodes betas and the afferent connectivity weights (can you recover the connectivity matrix?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
