{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Expanding on Ito et al. (2017) to recover simulated task activity and connectivity matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "sys.path.append('../../utils/')\n",
    "\n",
    "# Primary module with most model functions\n",
    "import model\n",
    "\n",
    "# Module for FC regression\n",
    "import multregressionconnectivity as mreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lambda x: np.tanh(x)\n",
    "\n",
    "inv_phi = lambda x: np.arctanh(x)\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural network model setup\n",
    "\n",
    "In this notebook we expand on simulations described in [Ito et al. (2017)](https://www.nature.com/articles/s41467-017-01000-w.pdf). Ito et al. propose a dynamic neural network model to simulate resting state and task data. Accordingly change in activity in each node is a function of the local connectivity determined by $s$, global connectivity determined by $g$ and task activity for that node described in $I$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt}\\tau_i = -x_i(t) + s\\phi\\big(x_i(t)\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + I_i(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where transformation function $\\phi$ is\n",
    "\\begin{equation*}\n",
    "\\phi(x) = \\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{e^{2x}-1}{e^{2x}+1}\n",
    "\\end{equation*}\n",
    "\n",
    "This transformation is intended to introduce *\"a nonlinearity to the interactions among units that is\n",
    "similar to aggregate nonlinearity from neuronal action potentials\"* as explained in [Cole et al. (2016)](https://www.nature.com/articles/nn.4406.pdf). The effect of this transformation can be seen below in the attenuated signal of the transformed timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 6\n",
    "plt.rcParams[\"figure.figsize\"][1] = 5\n",
    "a = np.random.normal(size=100)\n",
    "pa = phi(a)\n",
    "plt.plot(a, label=\"Untransformed\")\n",
    "plt.plot(pa, label=\"Transformed\")\n",
    "plt.axhline(y=1,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axhline(y=-1,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ito et al. (2017) $\\tau_i$, $s$, $g$ and $dt$ are set to 1. This simplifies the equation to:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_i(t) + \\frac{dx_i}{dt} = \\phi\\big(x_i(t)\\big) + \\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big) + I_i(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create structural and synaptic network***\n",
    "\n",
    "One hub and two local networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameters for subject's networks\n",
    "ncommunities = 3\n",
    "innetwork_dsity = .60\n",
    "outnetwork_dsity = .08\n",
    "hubnetwork_dsity = .25\n",
    "\n",
    "nodespercommunity = 35\n",
    "totalnodes = nodespercommunity*ncommunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in this matrix:\n",
    "\n",
    "`W[..., x]` : column x of matrix denotes all outgoing connection weights from node x  \n",
    "`W[x, ...]` : row x of matrix denotes all incoming connection weights to node x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up simulation parameters\n",
    "dt = 1.0\n",
    "tau = 1.0\n",
    "g = 1.0\n",
    "s = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task activity \n",
    "\n",
    "***Hub network stimulation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ci = np.repeat(np.arange(ncommunities),nodespercommunity) # Construct a community affiliation vector\n",
    "hub_ind = np.where(Ci==0)[0] # Identify the regions associated with the hub network (hub network is by default the 0th network)\n",
    "\n",
    "# Set number of time points for each task\n",
    "Tmax = 100000 \n",
    "\n",
    "T = np.arange(0,Tmax,dt)\n",
    "    \n",
    "# Construct timing array for convolution -- this timing is irrespective of the task being performed\n",
    "# Tasks are only determined by which nodes are stimulated\n",
    "tasktiming = np.zeros((1,len(T)))\n",
    "for t in range(len(T)):\n",
    "    if t%2000>500 and t%2000<1000:\n",
    "        tasktiming[0,t] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block design where stimulus is ON for 500 ms every 2 seconds looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T[:10000], tasktiming[0,:10000])\n",
    "plt.ylim(top = 1.2, bottom = -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimtimes = {}\n",
    "\n",
    "topdown_only = range(1,2)\n",
    "task = 1\n",
    "\n",
    "taskcount = task-np.min(topdown_only)\n",
    "stimsize = np.floor(nodespercommunity/3.0)\n",
    "stim_nodes = np.arange((taskcount)*stimsize,(taskcount)*stimsize+stimsize,dtype=int)\n",
    "stimtimes[task] = np.zeros((totalnodes,len(T)))\n",
    "\n",
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activated nodes in the hub network *only* (making it a top-down task) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`taskdata` is an $n$ by $t$ matrix containing the timeseries for each node where $n$-rows are for nodes and $t$ columns are for the time points.\n",
    "\n",
    "It is generated by updating each column (each time point) for **all nodes**  \n",
    "\n",
    "At each time point the differential equation describing the change in activity is solved using the [Runge-Kutta second order method](https://lpsa.swarthmore.edu/NumInt/NumIntSecond.html). Runge-Kutta methods are used to discretize the problem of updating values for continuous time when solving differential equations. Ito et al. hypothesize the differential equation determining the amount of change in each timestep as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{dx_i}{dt} = \\frac{-x_i(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(x_j(t)\\big)\\Bigg) + s\\phi\\big(x_i(t)\\big) + I_i(t)}{\\tau_i}\n",
    "\\end{equation*}\n",
    "\n",
    "Thus `taskdata` for all nodes $x_i$ consists of the current activity plus a weighted sum of approximate changes in activity calculated using the differential equation.\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+dt) = x_{i}(t) + \\frac{k1_{i}+k2_{i}}{2}\n",
    "\\end{equation*}\n",
    "\n",
    "The first derivative based on $t(0)$ that is used for the approximation is\n",
    "\n",
    "\\begin{equation*}\n",
    "k1_{i} = \\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}\n",
    "\\end{equation*}\n",
    "\n",
    "$\\hat{I}_{i}(t)$ is the spontaneous activity that is the sum of randomly generated noise and task-related stimulation ($\\hat{I}_{i}(t) = {I}_{i}(t)+\\epsilon(t)$). Since the column-vector of task-related stimulation activity is very sparse ($|I_{i}(t)| \\neq 0$ only for $i$ that is the third of the hub nodes and only for a short window of timepoints $t$) **most of the activity feeds into updating the activity of a node is noise (which in this framework is the equivalent of rest activity)**.\n",
    "\n",
    "Using this slope the first intermediate approximation at the endpoint is\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}^*(t+dt) = x_{i}(t) + k1_{i} dt\n",
    "\\end{equation*}\n",
    "\n",
    "and the second order approximation for the change in activity is\n",
    "\n",
    "\\begin{equation*}\n",
    "k2_{i} = \\frac{-x_{i}^*(t+dt) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(x_{i}^*(t+dt)\\big) + \\hat{I}_{i}(t+1)}{\\tau}\n",
    "\\end{equation*}\n",
    "\n",
    "If we discretize and work through the algebra the row-wise (node-centric) 'expanded' GLM for the column-wise (timepoint-centric) generated data using the Runge-Kutte method would be:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + dt\\frac{k1_{i}+k2_{i}}{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + dt\\frac{\\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}+\\frac{-x_{i}^*(t+dt) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(x_{i}^*(t+dt)\\big) + \\hat{I}_{i}(t+1)}{\\tau}}{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing $x_{i}^*(t+dt)$\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + dt\\frac{\\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}+\\frac{-x_{i}(t) - k1_{i} dt + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(x_{i}(t) + k1_{i} dt\\big) + \\hat{I}_{i}(t+1)}{\\tau}}{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting ride of $s, g, \\tau, dt$ (as they are 1 in these simulations) cleaning up and moving the denominator\n",
    "\n",
    "\\begin{equation*}\n",
    "2x_{i}(t+1) = \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t) - k1_{i} + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + \\phi\\big(x_{i}(t) + k1_{i} \\big) + \\hat{I}_{i}(t+1)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing $k1_i$\n",
    "\n",
    "\\begin{equation*}\n",
    "2x_{i}(t+1) = \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t) - \\Bigg[-x_{i}(t) + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg] + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + \\phi\\big(x_{i}(t) + \\Bigg[-x_{i}(t) + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg]\\big) + \\hat{I}_{i}(t+1)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup\n",
    "\n",
    "\\begin{equation*}\n",
    "2x_{i}(t+1) = x_{i}(t) + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + \\phi\\Bigg(\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg) + \\hat{I}_{i}(t+1)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this equation to expand the traditinal GLM. A traditional GLM would have modeled\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t) = h(t) \\circledast I(t) + \\epsilon_i(t)\n",
    "\\end{equation*}\n",
    "\n",
    "that is the activity of a voxel at a given time point would have been a function of the convolved task activity for that node at that time point plus some noise (For these simulations we ignore other movement confounds etc. included in level 1 models in real data).  \n",
    "\n",
    "With the expanded model derived from the approximation of the differential equation we model the value at the next time step of a given node ($x_{i}(t+1)$) as a function of their activity in the current time step ($x_{i}(t)$), the transformed activity in the next time step from all other nodes weighted by their connection weights to the given node ($\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg)$), the transformed activity in the current time step resulting from other nodes, self and task ($\\phi\\Bigg(\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg)$) and task activity for that node in the next time step ($\\hat{I}_{i}(t+1)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "#taskdata = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "#                                          I=stimtimes[task], noise=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending GLM (eGLM) to recover true task activity\n",
    "\n",
    "Note: Extending the GLM in this way is intended to account for the connectivity between nodes and how **task** activity in the previous step affects task activity in the current step for a given node. I don't think this is the same thing as 'subtracting out' resting state to look at the remaining task activity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting task activity knowing the connectivity matrix\n",
    "\n",
    "With real data we can estimate the weight matrix from resting state but we wouldn't know which nodes a task activates. Thus we wouldn't have access to $\\hat{I}_i(t)$ but only to $\\hat{I}(t)$, i.e. assume that the regressor has the same effect on all nodes. \n",
    "\n",
    "Running the model\n",
    "\n",
    "\\begin{equation*}\n",
    "2x_{i}(t+1) = x_{i}(t) + \\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}(t+1)\\big)\\Bigg) + \\phi\\Bigg(\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}(t)\\big)\\Bigg) + \\phi\\big(x_{i}(t)\\big) + \\hat{I}(t)\\Bigg) + \\hat{I}(t+1)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using first third of the data for speed of estimation\n",
    "taskdata_short = copy.copy(taskdata[:,:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = copy.copy(taskdata_short)\n",
    "I = copy.copy(stimtimes[task][:,:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntimepoints = y.shape[1]\n",
    "nregions = y.shape[0]\n",
    "\n",
    "#Initialize empty variables\n",
    "ucr_task = np.zeros((nregions))\n",
    "ext_cur_node = np.zeros((nregions)) \n",
    "ext_other_ns_next_spont = np.zeros((nregions)) \n",
    "ext_phi_others_cur_spont = np.zeros((nregions)) \n",
    "ext_task = np.zeros((nregions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in range(0, nregions):\n",
    "    \n",
    "    cur_y = y[region,:]\n",
    "    incoming_connections = W[region, :]\n",
    "    incoming_connections = np.delete(incoming_connections,region)\n",
    "    #task_reg = I[region,:]\n",
    "    task_reg = I[0,:]\n",
    "\n",
    "    ucr_mod = sm.OLS(cur_y, task_reg)\n",
    "    ucr_res = ucr_mod.fit()\n",
    "    ucr_task[region] = ucr_res.params[0]\n",
    "\n",
    "    #Extended model \n",
    "    next_y = 2*cur_y[1:] #shift column up to predict next multiplied activity\n",
    "\n",
    "    cur_y = cur_y[:-1] #drop last time point\n",
    "\n",
    "    drop_region = [region]\n",
    "    other_ns_next_spont = np.delete(y, drop_region, axis=0)[:,1:] #dropping first col/timepoint\n",
    "    other_ns_next_spont = other_ns_next_spont.T\n",
    "    other_ns_next_spont = np.apply_along_axis(phi, 0, other_ns_next_spont)\n",
    "    other_ns_next_spont = np.sum(other_ns_next_spont*incoming_connections, axis = 1)\n",
    "\n",
    "    other_ns_cur_spont = np.delete(y, drop_region, axis=0)[:,:-1] #dropping last col/timepoint\n",
    "    other_ns_cur_spont = other_ns_cur_spont.T\n",
    "    other_ns_cur_spont = np.apply_along_axis(phi, 0, other_ns_cur_spont)\n",
    "    other_ns_cur_spont = np.sum(other_ns_cur_spont*incoming_connections, axis = 1)\n",
    "\n",
    "    cur_y_phi = phi(cur_y)\n",
    "\n",
    "    cur_n_cur_spont = task_reg[:-1]\n",
    "    \n",
    "    phi_others_cur_spont = phi(other_ns_cur_spont + cur_y_phi + cur_n_cur_spont)\n",
    "    \n",
    "    cur_n_next_spont = task_reg[1:]\n",
    "\n",
    "    ext_des_mat = np.concatenate((cur_y.reshape(-1,1), other_ns_next_spont.reshape(-1,1)), 1)\n",
    "    ext_des_mat = np.concatenate((ext_des_mat, phi_others_cur_spont.reshape(-1,1)), 1)\n",
    "    ext_des_mat = np.concatenate((ext_des_mat, cur_n_next_spont.reshape(-1,1)), 1)\n",
    "\n",
    "    ext_mod = sm.OLS(next_y, ext_des_mat)\n",
    "    ext_res = ext_mod.fit()\n",
    "    ext_params = ext_res.params\n",
    "\n",
    "    ext_cur_node[region] = ext_params[0]\n",
    "    ext_other_ns_next_spont[region] = ext_params[1]\n",
    "    ext_phi_others_cur_spont[region] = ext_params[2]\n",
    "    ext_task[region] = ext_params[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task betas reduced after correction?\n",
    "\n",
    "Yes, but not the level of 'true' activity (0.5) for all activated nodes.  \n",
    "\n",
    "Note the three levels in the classic GLM: true activity estimates bleed more into the hub network nodes compared to the local network nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_mag = 0.5\n",
    "true_task_stim = np.zeros(totalnodes)\n",
    "true_task_stim[stim_nodes] = stim_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", label = \"Extended GLM\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deviance in over- and under-estimaton for the stimulated vs. non-stimulated nodes in the extended GLM are not different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(ucr_task-true_task_stim), color = \"blue\", label = \"Classic GLM\")\n",
    "plt.plot(abs(ext_task-true_task_stim), color = \"green\", label = \"Extended GLM\")\n",
    "plt.axhline(y=0,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.ylabel('|Estimate - True|',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if  \n",
    "1. The mean of the task coefficients estimated for non-stimulated nodes is not different from the true value of 0 \n",
    "2. the mean of the task coefficients estimated for the stimulated nodes is not different from the true value 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(np.delete(ext_task, stim_nodes), np.repeat(0, 94))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(ext_task[stim_nodes], np.repeat(0.5,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizable function for eGLM\n",
    "\n",
    "The loop above that runs an extended GLM on each node's timeseries accounting for its local and global connectivity uses the simplified differential equation that depends on the set values of the parameters.  \n",
    "\n",
    "But the parameters used in generating the neural network ($dt$, $\\tau$, $g$, $s$) need not be 1. Therefore the extended GLM model would not always simplify to the equation above. To be able to test this method of extending the traditional GLM more generally pn different network and task structures we need to algebraically write out the full equation including all the parameters that describes how activity in the next time step of each node is updated ($x_{i}(t+1)$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "k1_{i} = \\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + dt\\frac{\\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}+\\frac{-x_{i}(t) - k1_{i} dt + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(x_{i}(t) + k1_{i} dt\\big) + \\hat{I}_{i}(t+1)}{\\tau}}{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write out a general equation for $x_i(t+1)$ first we replace the $k1_i$ in the equation. Since $k1_i$ appears always in the context of $x_i(t)+k1_idt$ we plug in the formula for $k1_i$ into this expression and simplify\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t) + k1_{i}dt = x_{i}(t)+dt\\frac{-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)}{\\tau}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t) + k1_{i}dt = \\frac{\\tau-dt}{\\tau}x_{i}(t)+\\frac{dt}{\\tau}\\Bigg[g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg]\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use this expression in the formula of $x_{i}(t+1)$ \n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + \\frac{dt}{2\\tau}\\Bigg[-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t) - \\big(x_{i}(t) + k1_{i} dt\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(x_{i}(t) + k1_{i} dt\\big) + \\hat{I}_{i}(t+1)\\Bigg]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging in $x_{i}(t) + k1_{i}dt$\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + \\frac{dt}{2\\tau}\\Bigg[-x_{i}(t) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t) - \\big(\\frac{\\tau-dt}{\\tau}x_{i}(t)+\\frac{dt}{\\tau}\\Bigg[g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg]\\big) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(\\frac{\\tau-dt}{\\tau}x_{i}(t)+\\frac{dt}{\\tau}\\Bigg[g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg]\\big) + \\hat{I}_{i}(t+1)\\Bigg]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifying common terms\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = x_{i}(t) + \\frac{dt}{2\\tau}\\Bigg[\\frac{dt-2\\tau}{\\tau}x_{i}(t) + \\frac{\\tau-dt}{\\tau}\\Bigg[g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg] + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(\\frac{\\tau-dt}{\\tau}x_{i}(t)+\\frac{dt}{\\tau}\\Bigg[g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg]\\big) + \\hat{I}_{i}(t+1)\\Bigg]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting $x_{i}(t)$ outside the rest of the expression\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i}(t+1) = \\frac{2\\tau^2+dt(dt-2\\tau)}{2\\tau^2}x_{i}(t) + \\frac{dt}{2\\tau}\\Bigg[\\frac{\\tau-dt}{\\tau}\\Bigg(g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg) + g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t+1)\\big)\\Bigg) + s\\phi\\big(\\frac{\\tau-dt}{\\tau}x_{i}(t)+\\frac{dt}{\\tau}\\Bigg(g\\Bigg(\\sum_{j\\neq i}^{N} W_{ij}\\phi\\big(\\hat{I}_j(t)\\big)\\Bigg) + s\\phi\\big(x_{i}(t)\\big) + \\hat{I}_{i}(t)\\Bigg)\\big) + \\hat{I}_{i}(t+1)\\Bigg]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty messy expression. In words it describes the activity in the next time point for a node as a function of:\n",
    "- current node activity \n",
    "- current activity depending on connectivity with other nodes, local connectivity and task stimulation \n",
    "- activity in the next time step depending on connectivity with other nodes, first order approximation in the current node and task stimulation  \n",
    "all of which are weigted by different constants that depends on the time steps\n",
    "\n",
    "Since this is just the generalized form of the simplified extended GLM equation including all the terms that were previously omitted because their values were known to be 1 we should get the same results if we rewrite the code for the extended GLM with this equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ucr_glm(all_nodes_ts, task_reg):\n",
    "    nregions = all_nodes_ts.shape[0]\n",
    "    ucr_task_betas = np.zeros((nregions))\n",
    "    \n",
    "    for region in range(0, nregions):\n",
    "        cur_y = all_nodes_ts[region,:]\n",
    "        ucr_mod = sm.OLS(cur_y, task_reg)\n",
    "        ucr_res = ucr_mod.fit()\n",
    "        ucr_task_betas[region] = ucr_res.params[0]\n",
    "    \n",
    "    return ucr_task_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ext_glm(all_nodes_ts, task_reg, weight_matrix, dt, tau, g, s): \n",
    "    \n",
    "    nregions = all_nodes_ts.shape[0]\n",
    "    ext_task_betas = np.zeros((nregions))\n",
    "    \n",
    "    for region in range(0, nregions):\n",
    "        cur_y = all_nodes_ts[region,:]\n",
    "        incoming_connections = weight_matrix[region, :]\n",
    "        incoming_connections = np.delete(incoming_connections,region)\n",
    "        drop_region = [region]\n",
    "        \n",
    "        #DV\n",
    "        next_y = cur_y[1:] #shift column up to predict activity in next time point\n",
    "\n",
    "        #IV 1\n",
    "        cur_y = cur_y[:-1] #drop last time point\n",
    "        cur_y = ((2*(tau**2)+dt*(dt-2*tau))/(2*(tau**2)))*cur_y\n",
    "        \n",
    "        #IV 2\n",
    "        other_ns_cur_spont = np.delete(y, drop_region, axis=0)[:,:-1] #dropping last col/timepoint\n",
    "        other_ns_cur_spont = other_ns_cur_spont.T\n",
    "        other_ns_cur_spont = np.apply_along_axis(phi, 0, other_ns_cur_spont)\n",
    "        other_ns_cur_spont = np.sum(other_ns_cur_spont*incoming_connections, axis = 1) \n",
    "        other_ns_cur_spont = (dt/(2*tau))*((tau-dt)/tau)*g*other_ns_cur_spont\n",
    "        \n",
    "        #IV 3\n",
    "        cur_y_phi = all_nodes_ts[region,:]\n",
    "        cur_y_phi = cur_y_phi[:-1]\n",
    "        cur_y_phi = (dt/(2*tau))*((tau-dt)/tau)*s*phi(cur_y_phi)\n",
    "        \n",
    "        #IV 4\n",
    "        cur_n_task = (dt/(2*tau))*((tau-dt)/tau)*task_reg[:-1]\n",
    "        \n",
    "        #IV 5\n",
    "        other_ns_next_spont = np.delete(y, drop_region, axis=0)[:,1:] #dropping first col/timepoint\n",
    "        other_ns_next_spont = other_ns_next_spont.T\n",
    "        other_ns_next_spont = np.apply_along_axis(phi, 0, other_ns_next_spont)\n",
    "        other_ns_next_spont = np.sum(other_ns_next_spont*incoming_connections, axis = 1)\n",
    "        other_ns_next_spont = (dt/(2*tau))*g*other_ns_next_spont\n",
    "        \n",
    "        #IV 6\n",
    "        cur_n_first_appr = all_nodes_ts[region,:]\n",
    "        cur_n_first_appr = cur_n_first_appr[:-1]\n",
    "        cur_n_first_appr = ((tau-dt)/tau)*cur_n_first_appr\n",
    "        tmp = np.delete(all_nodes_ts, drop_region, axis=0)[:,:-1] #dropping last col/timepoint\n",
    "        tmp = tmp.T\n",
    "        tmp = np.apply_along_axis(phi, 0, tmp)\n",
    "        tmp = np.sum(tmp*incoming_connections, axis = 1) \n",
    "        tmp = (dt/tau)*g*tmp\n",
    "        cur_n_first_appr = cur_n_first_appr+tmp\n",
    "        tmp = all_nodes_ts[region,:]\n",
    "        tmp = tmp[:-1]\n",
    "        tmp = s*phi(tmp)\n",
    "        cur_n_first_appr = cur_n_first_appr+tmp\n",
    "        cur_n_first_appr = cur_n_first_appr+task_reg[:-1]\n",
    "        cur_n_first_appr = (dt/(2*tau))*s*phi(cur_n_first_appr)\n",
    "        \n",
    "        #IV 7\n",
    "        cur_n_next_task = (dt/(2*tau))*task_reg[1:]\n",
    "        \n",
    "        #All IVs in design matrix\n",
    "        ext_des_mat = np.concatenate((cur_y.reshape(-1,1), other_ns_cur_spont.reshape(-1,1)), 1)\n",
    "        ext_des_mat = np.concatenate((ext_des_mat, cur_y_phi.reshape(-1,1)), 1)\n",
    "        ext_des_mat = np.concatenate((ext_des_mat, cur_n_task.reshape(-1,1)), 1)\n",
    "        ext_des_mat = np.concatenate((ext_des_mat, other_ns_next_spont.reshape(-1,1)), 1)\n",
    "        ext_des_mat = np.concatenate((ext_des_mat, cur_n_first_appr.reshape(-1,1)), 1)\n",
    "        ext_des_mat = np.concatenate((ext_des_mat, cur_n_next_task.reshape(-1,1)), 1)\n",
    "\n",
    "        ext_mod = sm.OLS(next_y, ext_des_mat)\n",
    "        ext_res = ext_mod.fit()\n",
    "        ext_params = ext_res.params\n",
    "\n",
    "        ext_task_betas[region] = ext_params[6]\n",
    "    \n",
    "    return ext_task_betas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper around network simulation and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_network_task_glm(ncommunities = 3, \n",
    "                         innetwork_dsity = .60, \n",
    "                         outnetwork_dsity = .08, \n",
    "                         hubnetwork_dsity = .25, \n",
    "                         nodespercommunity = 35, \n",
    "                         plot_network = False,\n",
    "                         dt = 1, tau = 1, g = 1, s = 1, \n",
    "                         topdown = True, bottomup = False, \n",
    "                         local_com = 1, \n",
    "                         Tmax = 100000, \n",
    "                         plot_task = False, \n",
    "                         stimsize = np.floor(35/3.0), \n",
    "                         tasktiming = None, \n",
    "                         noise = 1):\n",
    "\n",
    "    totalnodes = nodespercommunity*ncommunities\n",
    "\n",
    "    # Construct structural matrix\n",
    "    S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                        innetwork_dsity=innetwork_dsity,\n",
    "                                        outnetwork_dsity=outnetwork_dsity,\n",
    "                                        hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                        nodespercommunity=nodespercommunity,\n",
    "                                        showplot=plot_network)\n",
    "    # Construct synaptic matrix\n",
    "    W = model.generateSynapticNetwork(S, showplot=plot_network)\n",
    "\n",
    "    if plot_network:\n",
    "        plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "        plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "        sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "        plt.xlabel('Regions')\n",
    "        plt.ylabel('Regions')\n",
    "        plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")\n",
    "\n",
    "    T = np.arange(0,Tmax,dt)\n",
    "\n",
    "    # Construct timing array for convolution -- this timing is irrespective of the task being performed\n",
    "    # Tasks are only determined by which nodes are stimulated\n",
    "    if tasktiming is None:\n",
    "        tasktiming = np.zeros((1,len(T)))\n",
    "        for t in range(len(T)):\n",
    "            if t%2000>500 and t%2000<1000:\n",
    "                tasktiming[0,t] = 1.0\n",
    "\n",
    "    if plot_task:\n",
    "        if len(T)>9999:\n",
    "            plt.plot(T[:10000], tasktiming[0,:10000])\n",
    "            plt.ylim(top = 1.2, bottom = -0.1)\n",
    "        else:\n",
    "            plt.plot(T, tasktiming[0,:])\n",
    "            plt.ylim(top = 1.2, bottom = -0.1)\n",
    "\n",
    "    stimtimes = np.zeros((totalnodes,len(T)))\n",
    "\n",
    "    # Construct a community affiliation vector\n",
    "    Ci = np.repeat(np.arange(ncommunities),nodespercommunity) \n",
    "\n",
    "    if topdown:\n",
    "        # Identify the regions associated with the hub network (hub network is by default the 0th network)\n",
    "        hub_ind = np.where(Ci==0)[0] \n",
    "        stim_nodes = np.arange(0, stimsize,dtype=int)\n",
    "    \n",
    "    if bottomup:\n",
    "        # Identify indices for one of the local communities\n",
    "        local_ind = np.where(Ci==local_com)[0] \n",
    "        # Identify efferent connections from local network to hub network\n",
    "        W_mask = np.zeros((W.shape))\n",
    "        W_mask[local_ind,hub_ind] = 1.0\n",
    "        local2hub_connects = np.multiply(W,W_mask)\n",
    "        local_regions_wcon = np.where(local2hub_connects!=0)[0]\n",
    "        local_regions_ncon = np.setdiff1d(local_ind,local_regions_wcon)\n",
    "        #Half of the stimulated local community nodes have hub connections while the other does not\n",
    "        stim_nodes = np.hstack((np.random.choice(local_regions_ncon, int(np.floor(stimsize/2)), replace=False),\n",
    "                                np.random.choice(local_regions_wcon, int(stimsize-np.floor(stimsize/2)), replace=False)))\n",
    "    \n",
    "    # When task is ON the activity for a stim_node at that time point is .5\n",
    "    for t in range(len(T)):\n",
    "        if tasktiming[0,t] == 1:\n",
    "            stimtimes[stim_nodes,t] = .5\n",
    "\n",
    "    out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau, I=stimtimes, noise=noise)\n",
    "    taskdata = out[0]\n",
    "\n",
    "    short_lim = np.floor(taskdata.shape[1]/3)\n",
    "    y = copy.copy(taskdata[:,:short_lim])\n",
    "\n",
    "    ucr_glm = run_ucr_glm(all_nodes_ts = y, task_reg = I[stim_nodes[0],:])\n",
    "    ext_glm = run_ext_glm(all_nodes_ts = y, task_reg = I[stim_nodes[0],:], \n",
    "                          weight_matrix = W, dt = dt, tau = tau, g = g, s = s)\n",
    "    \n",
    "    return(W, ucr_glm, ext_glm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different network structures\n",
    "\n",
    "Above we tested if true task activity can be recovered when accounting for connectivity in a neural network with one hub and two local networks.\n",
    "\n",
    "Various parameters control the structure of this network and they can be maniupulated \n",
    "\n",
    "Thing to modulate:   \n",
    "- hub and local network density  \n",
    "- local ($s$) and global ($g$) information transfer strength (change in conjunction)  \n",
    "- time step ($\\tau$)\n",
    "- number local networks   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing network density\n",
    "\n",
    "#### Increased innetwork density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increased innetwork density\n",
    "#innetwork_dsity = .60\n",
    "innetwork_dsity = .80\n",
    "#outnetwork_dsity = .08\n",
    "#hubnetwork_dsity = .25\n",
    "\n",
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_innetwork = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_innetwork = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_innetwork, color = \"blue\", label = \"Classic GLM (I)\")\n",
    "plt.plot(ext_glm_high_innetwork, color = \"green\", label = \"Extended GLM (I)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increased outnetwork density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increased innetwork density\n",
    "innetwork_dsity = .60\n",
    "#outnetwork_dsity = .08\n",
    "outnetwork_dsity = .15\n",
    "#hubnetwork_dsity = .25\n",
    "\n",
    "\n",
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_outnetwork = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_outnetwork = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_outnetwork, color = \"blue\", label = \"Classic GLM (O)\")\n",
    "plt.plot(ext_glm_high_outnetwork, color = \"green\", label = \"Extended GLM (O)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increased hub network density\n",
    "\n",
    "Increasing the hub network density might make the overestimation of the uncorrected GLM parameters for the non-stimulated nodes worse but how well it is can be corrected with eGLM doesn't seem affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increased innetwork density\n",
    "#innetwork_dsity = .60\n",
    "outnetwork_dsity = .08\n",
    "#hubnetwork_dsity = .25\n",
    "hubnetwork_dsity = .45\n",
    "\n",
    "\n",
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_hubnetwork = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_hubnetwork = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_hubnetwork, color = \"blue\", label = \"Classic GLM (H)\")\n",
    "plt.plot(ext_glm_high_hubnetwork, color = \"green\", label = \"Extended GLM (H)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing information transfer strength\n",
    "\n",
    "#### Increasing $g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innetwork_dsity = .60\n",
    "outnetwork_dsity = .08\n",
    "hubnetwork_dsity = .25\n",
    "\n",
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=3,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_g = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_g = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_g, color = \"blue\", label = \"Classic GLM (g)\")\n",
    "plt.plot(ext_glm_high_g, color = \"green\", label = \"Extended GLM (g)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=20,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_s = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_s = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_s, color = \"blue\", label = \"Classic GLM (s)\")\n",
    "plt.plot(ext_glm_high_s, color = \"green\", label = \"Extended GLM (s)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing $\\tau$\n",
    "\n",
    "#### Increasing $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=2,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_t = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_t = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_t, color = \"blue\", label = \"Classic GLM (t)\")\n",
    "plt.plot(ext_glm_high_t, color = \"green\", label = \"Extended GLM (t)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decreasing $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=.5,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_t2 = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_t2 = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_t2, color = \"blue\", label = \"Classic GLM (t2)\")\n",
    "plt.plot(ext_glm_high_t2, color = \"green\", label = \"Extended GLM (t2)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing number of local communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=4,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"][0] = 5\n",
    "plt.rcParams[\"figure.figsize\"][1] = 4\n",
    "sns.heatmap(W, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.title(\"Synaptic Weight Matrix -- Coupling Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimtimes[task] = np.zeros((4*nodespercommunity,len(T)))\n",
    "\n",
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5\n",
    "\n",
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_n = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_n = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 10\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_n, color = \"blue\", label = \"Classic GLM (n)\")\n",
    "plt.plot(ext_glm_high_n, color = \"green\", label = \"Extended GLM (n)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=105,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing temporal resolution\n",
    "\n",
    "#### Decreasing $dt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct structural matrix\n",
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.arange(0,Tmax,0.5)\n",
    "\n",
    "tasktiming = np.zeros((1,len(T)))\n",
    "for t in range(len(T)):\n",
    "    if t%2000>500 and t%2000<1000:\n",
    "        tasktiming[0,t] = 1.0\n",
    "        \n",
    "stimtimes[task] = np.zeros((ncommunities*nodespercommunity,len(T)))\n",
    "\n",
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5\n",
    "\n",
    "out = model.networkModel(W,Tmax=Tmax,dt=.5,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_low_dt = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_low_dt = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_low_dt, color = \"blue\", label = \"Classic GLM (dt)\")\n",
    "plt.plot(ext_glm_low_dt, color = \"green\", label = \"Extended GLM (dt)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=105,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing $dt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.arange(0,Tmax,2)\n",
    "\n",
    "tasktiming = np.zeros((1,len(T)))\n",
    "for t in range(len(T)):\n",
    "    if t%2000>500 and t%2000<1000:\n",
    "        tasktiming[0,t] = 1.0\n",
    "        \n",
    "stimtimes[task] = np.zeros((ncommunities*nodespercommunity,len(T)))\n",
    "\n",
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5\n",
    "\n",
    "out = model.networkModel(W,Tmax=Tmax,dt=2,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_high_dt = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_high_dt = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(ucr_glm_high_dt, color = \"blue\", label = \"Classic GLM (dt)\")\n",
    "plt.plot(ext_glm_high_dt, color = \"green\", label = \"Extended GLM (dt)\")\n",
    "plt.plot(true_task_stim, color = \"black\", label = \"True task activity\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=105,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different task structures\n",
    "\n",
    "The initial task was a top down task that stimulated nodes only in the hub network and trickled activity down to the other nodes.\n",
    "\n",
    "Other task activations are possible.\n",
    "\n",
    "Things to modulate:  \n",
    "- Number of nodes stimulated\n",
    "- Stimulating only local community\n",
    "- Stimulating both hub and local community\n",
    "- Magnitude of stimulation (different from 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing number of stimulated nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimtimes = {}\n",
    "\n",
    "topdown_only = range(1,2)\n",
    "task = 1\n",
    "\n",
    "taskcount = task-np.min(topdown_only)\n",
    "stimsize = np.floor(nodespercommunity/2.0)\n",
    "stim_nodes = np.arange((taskcount)*stimsize,(taskcount)*stimsize+stimsize,dtype=int)\n",
    "stimtimes[task] = np.zeros((totalnodes,len(T)))\n",
    "\n",
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5\n",
    "\n",
    "stim_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.networkModel(W,Tmax=Tmax,dt=dt,g=g,s=s,tau=tau,\n",
    "                                          I=stimtimes[task], noise=1)\n",
    "taskdata = out[0]\n",
    "noise = out[1]\n",
    "\n",
    "y = copy.copy(taskdata[:,:15000])\n",
    "\n",
    "ucr_glm_more_stimn = run_ucr_glm(all_nodes_ts = y, task_reg = I[0,:])\n",
    "ext_glm_more_stimn = run_ext_glm(all_nodes_ts = y, task_reg = I[0,:], weight_matrix = W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_true_task_stim = np.zeros(totalnodes)\n",
    "new_true_task_stim[stim_nodes] = stim_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 8\n",
    "plt.rcParams[\"figure.figsize\"][1] = 6\n",
    "plt.plot(ucr_task, color = \"blue\", alpha = 0.5, label = \"Classic GLM\")\n",
    "plt.plot(ext_task, color = \"green\", alpha = 0.5, label = \"Extended GLM\")\n",
    "plt.plot(true_task_stim, color = \"black\", alpha=.5, label = \"True task activity\")\n",
    "plt.plot(ucr_glm_more_stimn, color = \"blue\", label = \"Classic GLM (stimn)\")\n",
    "plt.plot(ext_glm_more_stimn, color = \"green\", label = \"Extended GLM (stimn)\")\n",
    "plt.plot(new_true_task_stim, color = \"black\", label = \"True task activity (stimn)\")\n",
    "plt.ylabel('Beta',fontsize=14)\n",
    "plt.xlabel('Node',fontsize=14)\n",
    "plt.axvline(x=35,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=70,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.axvline(x=105,linewidth=2, color='gray', ls = \"--\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulating only local community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = model.generateStructuralNetwork(ncommunities=ncommunities,\n",
    "                                    innetwork_dsity=innetwork_dsity,\n",
    "                                    outnetwork_dsity=outnetwork_dsity,\n",
    "                                    hubnetwork_dsity=hubnetwork_dsity,\n",
    "                                    nodespercommunity=nodespercommunity,\n",
    "                                    showplot=False)\n",
    "# Construct synaptic matrix\n",
    "W = model.generateSynapticNetwork(S, showplot=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimtimes = {}\n",
    "\n",
    "stimsize = np.floor(nodespercommunity/3.0)\n",
    "#stim_nodes = np.arange(0,stimsize,dtype=int)\n",
    "stimtimes[task] = np.zeros((totalnodes,len(T)))\n",
    "\n",
    "local_ind = np.where(Ci==1)[0] # Identify indices for one of the local communities\n",
    "# Identify efferent connections from local network to hub network\n",
    "W_mask = np.zeros((W.shape))\n",
    "W_mask[local_ind,hub_ind] = 1.0\n",
    "local2hub_connects = np.multiply(W,W_mask)\n",
    "local_regions_wcon = np.where(local2hub_connects!=0)[0]\n",
    "local_regions_ncon = np.setdiff1d(local_ind,local_regions_wcon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((np.random.choice(local_regions_ncon, int(np.floor(stimsize/2)), replace=False),\n",
    "np.random.choice(local_regions_wcon, int(stimsize-np.floor(stimsize/2)), replace=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When task is ON the activity for a stim_node at that time point is .5\n",
    "for t in range(len(T)):\n",
    "    if tasktiming[0,t] == 1:\n",
    "        stimtimes[task][stim_nodes,t] = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulating both hub and local community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing magnitude of stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accounting for whether and how the node is connected to other nodes improves the task estimates both stimulated and non-stimulated nodes\n",
    "    - Is the over- and underestimation real? If so, what is causing it?\n",
    "2. The improvement in task estimates when accounting for connectivity is NOT affected by:\n",
    "    - Network density\n",
    "    - Number of local communities\n",
    "3. The improvement in task estimates when accounting for connectivity IS affected by:\n",
    "    - Information transfer strength (both local and global)  \n",
    "    - $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
