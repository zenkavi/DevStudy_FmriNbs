{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating RL parameters using PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying [this notebook](https://github.com/ricardoV94/stats/blob/master/modelling/RL_PyMC.ipynb) to simulate data and estimate parameters for the Machine Game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation Function\n",
    "\n",
    "Initial data generation function uses an RL model with only two parameters $\\alpha$ and $\\beta$. Question for this notebook: can these parameters be recovered successfully by the different estimators (MLE vs. NUTS sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(alpha, beta, n=100, \n",
    "                  p_r={'high_var': [.95, .05], 'low_var': [.5,.5]},\n",
    "                  rs = np.array(([5.0, -495.0],[-5.0, 495.0],[10.0, -100.0],[-10.0, 100.0])),\n",
    "                  sQ = np.zeros((4, 2))\n",
    "                 ):\n",
    "    \n",
    "    # Need to denote both machine type and action\n",
    "    \n",
    "    # Pre-specify machines for each trial in a randomly balanced manner\n",
    "    if n%4 != 0:\n",
    "        print(\"Number of trials is not divisable by 4.\\nCreating trials for %s trials.\"%(str(n-(n%4))))\n",
    "        n = n-(n%4)\n",
    "    \n",
    "    machs = np.array([0,1,2,3])\n",
    "    machs = np.tile(machs, int(n/4))\n",
    "    np.random.shuffle(machs)\n",
    "    \n",
    "    # Initialize empty array that will be populated in the loop based on Q values\n",
    "    acts = np.zeros(n, dtype=np.int)\n",
    "    \n",
    "    # Generate by coin flip for machine with differing probabilities and outcomes\n",
    "    rews = np.zeros(n, dtype=np.int)\n",
    "\n",
    "    # Stores the expected value for each of 4 machines in each trial for each action\n",
    "    Qs = np.zeros((n, 4, 2))\n",
    "\n",
    "    # Initialize Q table\n",
    "    # Denotes expected value of each action\n",
    "    # Should look like [0, 0] for each machine\n",
    "    # *** The expected value of not playing should not change from 0! ***\n",
    "    # Could these initial expected values/beliefs also be estimated from data?\n",
    "    # E.g. what if kids have more optimistic priors about each machine though they learn at the same rate\n",
    "    Q = sQ.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        cur_machine = machs[i]\n",
    "        \n",
    "        # Apply the Softmax transformation\n",
    "        exp_Q = np.exp(beta*Q[cur_machine])\n",
    "        prob_a = exp_Q / np.sum(exp_Q)\n",
    "\n",
    "        # Simulate choice\n",
    "        a = np.random.choice([0, 1], p=prob_a)\n",
    "        \n",
    "        # Simulate reward if machine is played\n",
    "        if a == 1:\n",
    "    \n",
    "            # Before sampling reward determine which variance condition machine is in\n",
    "            if cur_machine>1:\n",
    "                cur_p = 'low_var'\n",
    "            else:\n",
    "                cur_p = 'high_var'\n",
    "\n",
    "            # Sample reward for current machine given its reward probs and outcome options\n",
    "            r = np.random.choice(rs[cur_machine], p = p_r[cur_p]) \n",
    "            \n",
    "            # Update Q table only if the machine is played\n",
    "            # And only the value of playing NOT of not playing\n",
    "            Q[cur_machine][a] = Q[cur_machine][a] + alpha * (r - Q[cur_machine][a])\n",
    "        \n",
    "        # If the machine is not played then Q remains unchanged and no reward is received\n",
    "        else:\n",
    "            r = 0.0\n",
    "\n",
    "        # Store values\n",
    "        acts[i] = a\n",
    "        rews[i] = r\n",
    "        #Qs[i] = Q.copy()\n",
    "        Qs[i] = Q\n",
    "\n",
    "    return machs, acts, rews, Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE likelihood functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_td(x, *args):\n",
    "    # Extract the arguments as they are passed by scipy.optimize.minimize\n",
    "    alpha, beta = x\n",
    "    machines, actions, rewards = args\n",
    "\n",
    "    # Initialize values\n",
    "    Q = np.zeros((4, 2))\n",
    "    log_prob_actions = np.zeros(len(actions))\n",
    "\n",
    "    for t, (m, a, r) in enumerate(zip(machines, actions, rewards)):\n",
    "        \n",
    "        # Apply the softmax transformation\n",
    "        Q_ = Q[m] * beta\n",
    "        #print('t: %s, m: %s, a: %s, r: %s, Q:[%s, %s]'%(str(t), str(m), str(a), str(r), str(Q[m,0]), str(Q[m, 1])))\n",
    "        log_prob_action = Q_ - scipy.special.logsumexp(Q_)\n",
    "\n",
    "        # Store the log probability of the observed action\n",
    "        log_prob_actions[t] = log_prob_action[a]\n",
    "\n",
    "        # Update the Q values for the next trial\n",
    "        # Q[a] = Q[a] + alpha * (r - Q[a])\n",
    "        Q[m][a] = Q[m][a] + alpha * (r - Q[m][a])\n",
    "\n",
    "    # Return the negative log likelihood of all observed actions\n",
    "    return -np.sum(log_prob_actions[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_td_vectorized(x, *args):\n",
    "    # Extract the arguments as they are passed by scipy.optimize.minimize\n",
    "    alpha, beta = x\n",
    "    machines, actions, rewards = args\n",
    "    n = len(actions)\n",
    "\n",
    "    # Create a list with the Q values of each trial\n",
    "    Qs = np.zeros((n, 4, 2), dtype=np.float)\n",
    "    \n",
    "    # The last Q values were never used, so there is no need to compute them\n",
    "    for t, (m, a, r) in enumerate(zip(machines[:-1], actions[:-1], rewards[:-1])):\n",
    "        Qs[t+1] = Qs[t]\n",
    "        Qs[t+1, m, a] = Qs[t, m, a] + alpha * (r - Qs[t, m, a])\n",
    "        Qs[t+1, m, 1-a] = Qs[t, m, 1-a]\n",
    "        #print('t: %s, m: %s, a: %s, r: %s, Q:[%s, %s]'%(str(t), str(m), str(a), str(r), str(Qs[t,m,0]), str(Qs[t,m, 1])))\n",
    "\n",
    "    # Apply the softmax transformation in a vectorized way\n",
    "    idx = list(zip(range(n),machines))\n",
    "    obs_Qs = [Qs[i] for i in idx]\n",
    "    Qs_ = np.array(obs_Qs) * beta\n",
    "    log_prob_actions = Qs_ - scipy.special.logsumexp(Qs_, axis=1)[:, None]\n",
    "\n",
    "    # Return the log_prob_actions for the observed actions\n",
    "    log_prob_obs_actions = log_prob_actions[np.arange(n), actions]\n",
    "    return -np.sum(log_prob_obs_actions[1:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_alpha = .65\n",
    "true_beta = 1.5\n",
    "n = 120\n",
    "machines, actions, rewards, all_Qs = generate_data(true_alpha, true_beta, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter recovery with MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [true_alpha, true_beta]\n",
    "result = scipy.optimize.minimize(llik_td, x0, args=(machines, actions, rewards), method='BFGS')\n",
    "print(result)\n",
    "print('')\n",
    "print(f'MLE: alpha = {result.x[0]:.2f} (true value = {true_alpha})')\n",
    "print(f'MLE: beta = {result.x[1]:.2f} (true value = {true_beta})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute true likelihood of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llik_td([true_alpha, true_beta], *(machines, actions, rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llik_td_vectorized([true_alpha, true_beta], *(machines, actions, rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Theano and pyMC3 functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating likelihood of data as an example of using theano tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(machine, action, reward,\n",
    "             Q,\n",
    "             alpha):\n",
    "    Q = tt.set_subtensor(Q[machine, action], Q[machine, action] + alpha * (reward - Q[machine, action]))\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the variables into appropriate Theano objects\n",
    "machines_ = theano.shared(np.asarray(machines, dtype='int16')) \n",
    "actions_ = theano.shared(np.asarray(actions, dtype='int16'))\n",
    "rewards_ = theano.shared(np.asarray(rewards, dtype='int16'))\n",
    "\n",
    "alpha = tt.scalar(\"alpha\")\n",
    "beta = tt.scalar(\"beta\")\n",
    "\n",
    "# Initialize the Q table\n",
    "Qs = tt.zeros((4,2), dtype='float64')\n",
    "\n",
    "# Compute the Q values for each trial\n",
    "Qs, updates = theano.scan(\n",
    "    fn=update_Q,\n",
    "    sequences=[machines_, actions_, rewards_],\n",
    "    outputs_info=[Qs],\n",
    "    non_sequences=[alpha])\n",
    "\n",
    "int_Qs = tt.zeros((1, 4,2), dtype='float64')\n",
    "\n",
    "Qs = tt.concatenate((int_Qs, Qs), axis=0)\n",
    "\n",
    "# Apply the softmax transformation\n",
    "idx = list(zip(range(n),machines)) #list of tuples\n",
    "obs_Qs = [Qs[tuple(i)] for i in idx]\n",
    "Qs_ = obs_Qs * beta\n",
    "log_prob_actions = Qs_ - pm.math.logsumexp(Qs_, axis=1)\n",
    "\n",
    "# Calculate the negative log likelihod of the observed actions\n",
    "log_prob_actions = log_prob_actions[tt.arange(actions_.shape[0]), actions_]\n",
    "neg_log_like = -tt.sum(log_prob_actions[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano_llik_td = theano.function(inputs=[alpha, beta], outputs=[neg_log_like], updates = updates)\n",
    "result = theano_llik_td(true_alpha, true_beta)\n",
    "float(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano likelihood calculator\n",
    "\n",
    "Wrapped up likelihood calculation in function that can be called by pyMC model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theano_llik_td(alpha, beta, machines, actions, rewards, n=120):\n",
    "    # Transform the variables into appropriate Theano objects\n",
    "    machines_ = theano.shared(np.asarray(machines, dtype='int16')) \n",
    "    actions_ = theano.shared(np.asarray(actions, dtype='int16'))\n",
    "    rewards_ = theano.shared(np.asarray(rewards, dtype='int16'))\n",
    "    \n",
    "    # Initialize the Q table\n",
    "    Qs = tt.zeros((4,2), dtype='float64')\n",
    "\n",
    "    # Compute the Q values for each trial\n",
    "    Qs, updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[machines_, actions_, rewards_],\n",
    "        outputs_info=[Qs],\n",
    "        non_sequences=[alpha])\n",
    "\n",
    "    int_Qs = tt.zeros((1, 4,2), dtype='float64')\n",
    "\n",
    "    Qs = tt.concatenate((int_Qs, Qs), axis=0)\n",
    "\n",
    "    # Apply the softmax transformation\n",
    "    idx = list(zip(range(n),machines)) #list of tuples\n",
    "    obs_Qs = [Qs[i] for i in idx]\n",
    "    Qs_ = obs_Qs * beta\n",
    "    log_prob_actions = Qs_ - pm.math.logsumexp(Qs_, axis=1)\n",
    "\n",
    "    # Calculate the negative log likelihod of the observed actions\n",
    "    log_prob_actions = log_prob_actions[tt.arange(actions_.shape[0]), actions_]\n",
    "    return tt.sum(log_prob_actions[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative theano likelihood calculator \n",
    "\n",
    "using a right action probabilities to compare to coin flips using a Bernoilli distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def right_action_probs(alpha, beta, machines, actions, rewards):\n",
    "    # Transform the variables into appropriate Theano objects\n",
    "    machines_ = theano.shared(np.asarray(machines, dtype='int16')) \n",
    "    actions_ = theano.shared(np.asarray(actions, dtype='int16'))\n",
    "    rewards_ = theano.shared(np.asarray(rewards, dtype='int16'))\n",
    "    \n",
    "    # Initialize the Q table\n",
    "    Qs = tt.zeros((4,2), dtype='float64')\n",
    "\n",
    "    # Compute the Q values for each trial\n",
    "    Qs, updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[machines_, actions_, rewards_],\n",
    "        outputs_info=[Qs],\n",
    "        non_sequences=[alpha])\n",
    "\n",
    "    int_Qs = tt.zeros((1, 4,2), dtype='float64')\n",
    "\n",
    "    Qs = tt.concatenate((int_Qs, Qs), axis=0)\n",
    "\n",
    "    # Apply the softmax transformation\n",
    "    idx = list(zip(range(n),machines)) #list of tuples\n",
    "    obs_Qs = [Qs[i] for i in idx]\n",
    "    Qs_ = obs_Qs * beta\n",
    "    log_prob_actions = Qs_ - pm.math.logsumexp(Qs_, axis=1)\n",
    "\n",
    "    # Calculate the negative log likelihod of the observed actions\n",
    "    \n",
    "    return tt.exp(log_prob_actions[:, 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter recovery using pyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_ = theano.shared(np.asarray(actions, dtype='int16'))\n",
    "\n",
    "with pm.Model() as m:\n",
    "    alpha = pm.Beta('alpha', 1, 1)\n",
    "    beta = pm.HalfNormal('beta', 10)\n",
    "\n",
    "    like = pm.Potential('like', theano_llik_td(alpha, beta, machines, actions, rewards))\n",
    "    \n",
    "    # The alternative gave some less stable estimates so sticking to the standard for now\n",
    "    # action_probs = right_action_probs(alpha, beta, machines, actions, rewards)\n",
    "    # like = pm.Bernoulli('like', p=action_probs, observed=actions_)\n",
    "    \n",
    "    tr = pm.sample(draws=2000, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.get_values('alpha', combine=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "- Can pyMC recover parameters better for the whole range?\n",
    "    - Plot True vs. Estimated plots for MLE vs. NUTS (with credible interval) for full range of combination\n",
    "- Data generation functions for different RL models\n",
    "- Compare parameter recoverability for all RL models \n",
    "    - Preferably using only one  \n",
    "- Fit to one subject's data\n",
    "- Fit to all subjects' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE vs NUTS for other combinations of $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap all the steps pre output into a function\n",
    "def get_mle_nuts_est(true_alpha, true_beta, n=120, mle_niters = 50):\n",
    "\n",
    "    # Generate data\n",
    "    machines, actions, rewards, all_Qs = generate_data(true_alpha, true_beta, n)\n",
    "    true_llik = llik_td_vectorized([true_alpha, true_beta], *(machines, actions, rewards))\n",
    "\n",
    "    # MLE estimate starting from true value\n",
    "    x0 = [true_alpha, true_beta]\n",
    "    result = scipy.optimize.minimize(llik_td_vectorized, x0, args=(machines, actions, rewards), method='BFGS')\n",
    "    mle_alpha_ts = result.x[0]\n",
    "    mle_beta_ts = result.x[1]\n",
    "    mle_llik_ts = result.fun\n",
    "    \n",
    "    # MLE estimate starting from value sampled from prior\n",
    "    print(\"Starting MLE iterations with random starts...\")\n",
    "    \n",
    "    mle_iters = pd.DataFrame([])\n",
    "    for i in range(mle_niters):\n",
    "        random_alpha_start = np.random.beta(1,1)\n",
    "        random_beta_start = scipy.stats.halfnorm(scale=10).rvs()\n",
    "        x0 = [random_alpha_start, random_beta_start]\n",
    "        result = scipy.optimize.minimize(llik_td_vectorized, x0, args=(machines, actions, rewards), method='BFGS')\n",
    "        cur_alpha_est = result.x[0]\n",
    "        cur_beta_est = result.x[1]\n",
    "        cur_llik = result.fun\n",
    "        mle_iters = mle_iters.append({\"true_alpha\": true_alpha,\n",
    "                                      \"true_beta\": true_beta,\n",
    "                                      'random_alpha_start':random_alpha_start,\n",
    "                                      'random_beta_starts': random_beta_start,\n",
    "                                      'cur_alpha_est': cur_alpha_est,\n",
    "                                      'cur_beta_est': cur_beta_est,\n",
    "                                      'cur_llik': cur_llik}, ignore_index=True)\n",
    "\n",
    "    print(\"Done with MLE iterations with random starts.\")\n",
    "    \n",
    "    mle_alpha_ave = np.mean(mle_iters.cur_alpha_est)\n",
    "    mle_alpha_std = np.std(mle_iters.cur_alpha_est)\n",
    "    mle_beta_ave = np.mean(mle_iters.cur_beta_est)\n",
    "    mle_beta_std = np.std(mle_iters.cur_beta_est)\n",
    "    mle_llik_ave = np.mean(mle_iters.cur_llik)\n",
    "    mle_llik_std = np.std(mle_iters.cur_llik)\n",
    "    \n",
    "    # NUTS estimate\n",
    "    actions_ = theano.shared(np.asarray(actions, dtype='int16'))\n",
    "    with pm.Model() as m:\n",
    "        alpha = pm.Beta('alpha', 1, 1)\n",
    "        beta = pm.HalfNormal('beta', 10)\n",
    "        like = pm.Potential('like', theano_llik_td(alpha, beta, machines, actions, rewards, n))\n",
    "        tr = pm.sample()\n",
    "    \n",
    "    nuts_alpha_ave = np.mean(tr.alpha)\n",
    "    nuts_beta_ave = np.mean(tr.beta)\n",
    "    nuts_alpha_std = np.std(tr.alpha)\n",
    "    nuts_beta_std = np.std(tr.beta)\n",
    "    nuts_llik = llik_td_vectorized([nuts_alpha_ave, nuts_beta_ave], *(machines, actions, rewards))\n",
    "\n",
    "    # Output:\n",
    "    est_df = pd.DataFrame(data={\"true_alpha\": true_alpha,\n",
    "                                \"true_beta\": true_beta,\n",
    "                                \"true_llik\": true_llik,\n",
    "                                \"mle_alpha_ts\": mle_alpha_ts,\n",
    "                                \"mle_beta_ts\": mle_beta_ts,\n",
    "                                \"mle_llik_ts\": mle_llik_ts,\n",
    "                                \"mle_alpha_ave\":mle_alpha_ave,\n",
    "                                \"mle_beta_ave\": mle_beta_ave,\n",
    "                                \"mle_alpha_std\":mle_alpha_std,\n",
    "                                \"mle_beta_std\": mle_beta_std,\n",
    "                                \"mle_llik_ave\": mle_llik_ave,\n",
    "                                \"mle_llik_std\":mle_llik_std,\n",
    "                                \"nuts_alpha_ave\": nuts_alpha_ave,\n",
    "                                \"nuts_beta_ave\": nuts_beta_ave,\n",
    "                                \"nuts_alpha_std\": nuts_alpha_std,\n",
    "                                \"nuts_beta_std\": nuts_beta_std,\n",
    "                                \"nuts_llik\": nuts_llik}, index=[0])\n",
    "    \n",
    "    nuts_posteriors = pd.DataFrame(data={\"true_alpha\": true_alpha,\n",
    "                                         \"true_beta\": true_beta,\n",
    "                                         \"alpha\": pd.Series(tr.get_values('alpha')),\n",
    "                                        \"beta\": pd.Series(tr.get_values('beta'))})\n",
    "    \n",
    "    #return {\"est_df\": est_df, \"mle_iters\": mle_iters, \"nuts_posteriors\": nuts_posteriors}\n",
    "    return (est_df,  mle_iters, nuts_posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLE iterations with random starts...\n",
      "Done with MLE iterations with random starts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [beta, alpha]\n",
      "Sampling 2 chains, 5 divergences: 100%|██████████| 2000/2000 [00:41<00:00, 48.68draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "true_alpha = .65\n",
    "true_beta = 1.5\n",
    "est_df, mle_iters, nuts_posteriors = get_mle_nuts_est(true_alpha, true_beta, mle_niters = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_alpha</th>\n",
       "      <th>true_beta</th>\n",
       "      <th>true_llik</th>\n",
       "      <th>mle_alpha_ts</th>\n",
       "      <th>mle_beta_ts</th>\n",
       "      <th>mle_llik_ts</th>\n",
       "      <th>mle_alpha_ave</th>\n",
       "      <th>mle_beta_ave</th>\n",
       "      <th>mle_alpha_std</th>\n",
       "      <th>mle_beta_std</th>\n",
       "      <th>mle_llik_ave</th>\n",
       "      <th>mle_llik_std</th>\n",
       "      <th>nuts_alpha_ave</th>\n",
       "      <th>nuts_beta_ave</th>\n",
       "      <th>nuts_alpha_std</th>\n",
       "      <th>nuts_beta_std</th>\n",
       "      <th>nuts_llik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.004668</td>\n",
       "      <td>0.84839</td>\n",
       "      <td>4.371606</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.705525</td>\n",
       "      <td>11.220852</td>\n",
       "      <td>0.396655</td>\n",
       "      <td>3.939107</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>9.964432e-08</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>9.674988</td>\n",
       "      <td>0.269468</td>\n",
       "      <td>5.853325</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_alpha  true_beta  true_llik  mle_alpha_ts  mle_beta_ts  mle_llik_ts  \\\n",
       "0        0.65        1.5   3.004668       0.84839     4.371606     2.772589   \n",
       "\n",
       "   mle_alpha_ave  mle_beta_ave  mle_alpha_std  mle_beta_std  mle_llik_ave  \\\n",
       "0       0.705525     11.220852       0.396655      3.939107      2.772589   \n",
       "\n",
       "   mle_llik_std  nuts_alpha_ave  nuts_beta_ave  nuts_alpha_std  nuts_beta_std  \\\n",
       "0  9.964432e-08        0.542361       9.674988        0.269468       5.853325   \n",
       "\n",
       "   nuts_llik  \n",
       "0   2.772589  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_df.to_csv(\"est_df_alpha_%s_beta_%s.csv\"%(str(true_alpha), str(true_beta)), index=False)\n",
    "mle_iters.to_csv(\"mle_iters_alpha_%s_beta_%s.csv\"%(str(true_alpha), str(true_beta)), index=False)\n",
    "nuts_posteriors.to_csv(\"nuts_posteriors_alpha_%s_beta_%s.csv\"%(str(true_alpha), str(true_beta)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
